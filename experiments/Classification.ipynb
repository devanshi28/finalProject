{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing required packages\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "from spacy import displacy\n",
    "#from spacy.lang.en import English\n",
    "#parser = English()\n",
    "\n",
    "#from tqdm import tqdm\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, MaxAbsScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin \n",
    "\n",
    "#from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up display area to show dataframe in jupyter qtconsole\n",
    "\n",
    "#pd.set_option('display.height', 1000)\n",
    "#pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 50)\n",
    "#pd.set_option('display.width', 1000)\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devanshi\\Desktop\\finalProject\\data\\asap-sas\n"
     ]
    }
   ],
   "source": [
    "myDir = Path.cwd().parents[0]\n",
    "dataFolder = myDir / 'data/asap-sas'\n",
    "ratingsFolder = myDir / 'data/ratings'\n",
    "\n",
    "print(dataFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>subject</th>\n",
       "      <th>studentGrade</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>Score1</th>\n",
       "      <th>styleScore</th>\n",
       "      <th>totalChars</th>\n",
       "      <th>total_words</th>\n",
       "      <th>words_no_punct</th>\n",
       "      <th>words_no_punct_no_stop</th>\n",
       "      <th>count_content_words</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>maturity</th>\n",
       "      <th>concreteness</th>\n",
       "      <th>content_only_text</th>\n",
       "      <th>function_based_text</th>\n",
       "      <th>function_only_text</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>English</td>\n",
       "      <td>10</td>\n",
       "      <td>One trait that describes rose is hard-working....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4.173913</td>\n",
       "      <td>5.487419</td>\n",
       "      <td>2.449177</td>\n",
       "      <td>trait  that  describes  rose  is  hard working...</td>\n",
       "      <td>one __NOUN__ __ADJ__ __VERB__ __VERB__ __VERB_...</td>\n",
       "      <td>One  - .  I  this  because  she  to  , but  sh...</td>\n",
       "      <td>NUM NOUN ADJ VERB VERB VERB ADV PUNCT VERB PUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>English</td>\n",
       "      <td>10</td>\n",
       "      <td>First the author has an introduction to grab t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.333607</td>\n",
       "      <td>2.461765</td>\n",
       "      <td>First  author  has  introduction  grab  reader...</td>\n",
       "      <td>__ADV__ the __NOUN__ __VERB__ an __NOUN__ to _...</td>\n",
       "      <td>the  an  to  the  's  .  ,  the  if  in  the  ...</td>\n",
       "      <td>ADV DET NOUN VERB DET NOUN PART VERB DET NOUN ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EssaySet  subject  studentGrade  \\\n",
       "0         7  English            10   \n",
       "1         9  English            10   \n",
       "\n",
       "                                           EssayText  Score1  styleScore  \\\n",
       "0  One trait that describes rose is hard-working....       1           1   \n",
       "1  First the author has an introduction to grab t...       1           1   \n",
       "\n",
       "   totalChars  total_words  words_no_punct  words_no_punct_no_stop  \\\n",
       "0         120           27              23                      12   \n",
       "1         190           38              33                      18   \n",
       "\n",
       "   count_content_words  count_stopwords  avg_word_len  maturity  concreteness  \\\n",
       "0                   15               11      4.173913  5.487419      2.449177   \n",
       "1                   20               15      4.666667  5.333607      2.461765   \n",
       "\n",
       "                                   content_only_text  \\\n",
       "0  trait  that  describes  rose  is  hard working...   \n",
       "1  First  author  has  introduction  grab  reader...   \n",
       "\n",
       "                                 function_based_text  \\\n",
       "0  one __NOUN__ __ADJ__ __VERB__ __VERB__ __VERB_...   \n",
       "1  __ADV__ the __NOUN__ __VERB__ an __NOUN__ to _...   \n",
       "\n",
       "                                  function_only_text  \\\n",
       "0  One  - .  I  this  because  she  to  , but  sh...   \n",
       "1  the  an  to  the  's  .  ,  the  if  in  the  ...   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  NUM NOUN ADJ VERB VERB VERB ADV PUNCT VERB PUN...  \n",
       "1  ADV DET NOUN VERB DET NOUN PART VERB DET NOUN ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataFolder/'training.csv', header=0)  #read data into dataframe\n",
    "df.head(2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1339, 19)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Take only essay set 1\n",
    "set_1 = df[(df['EssaySet'] == 1)].copy()\n",
    "set_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, (ax1, ax2) = plt.subplots(nrows=1,ncols=2, figsize=(10,5), )\n",
    "\n",
    "sns.countplot(x=\"Score1\", data=set_1, orient='v', hue=\"Score1\", ax=ax1)\n",
    "sns.countplot(x=\"styleScore\", data=set_1, orient='v', hue=\"styleScore\", ax=ax2)\n",
    "\n",
    "#Customise title\n",
    "plt.suptitle(\"Original vs Normalized\", y = 1.05, fontsize=20)\n",
    "ax1.set_title(\"Original\",  y = 1)\n",
    "ax2.set_title(\"Normalized (MinMax)\", y = 1)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, cohen_kappa_score\n",
    "#from sklearn.metrics import accuracy_score, mean_squared_error, r2_score, cohen_kappa_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1339, 1) (1339,)\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42)\n",
    "\n",
    "X = set_1[['EssayText','Score1']].copy()\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "y= X.pop('Score1')\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 1069 Test: 270\n",
      "(0.607979797979798, 0.6100445319707615, 0.6044697165276098, None)\n",
      "(0.6074074074074074, 0.6074074074074074, 0.6074074074074074, None)\n",
      "(0.6022334455667789, 0.6074074074074074, 0.5999404787516314, None)\n",
      "0.4703236910776747\n",
      "Train: 1070 Test: 269\n",
      "(0.5598441152946967, 0.5481060606060606, 0.551594746716698, None)\n",
      "(0.5427509293680297, 0.5427509293680297, 0.5427509293680297, None)\n",
      "(0.5500850805726746, 0.5427509293680297, 0.5440947060314183, None)\n",
      "0.38369407294266666\n",
      "Train: 1071 Test: 268\n",
      "(0.6161849143358865, 0.6061205862410681, 0.6020678910186769, None)\n",
      "(0.6007462686567164, 0.6007462686567164, 0.6007462686567164, None)\n",
      "(0.6030185605435546, 0.6007462686567164, 0.5918339114557791, None)\n",
      "0.45949410035058624\n",
      "Train: 1073 Test: 266\n",
      "(0.5660348758709415, 0.5756276312981394, 0.5699189464923526, None)\n",
      "(0.5639097744360902, 0.5639097744360902, 0.5639097744360902, None)\n",
      "(0.5610522186634598, 0.5639097744360902, 0.5616281798039836, None)\n",
      "0.41567246146271264\n",
      "Train: 1073 Test: 266\n",
      "(0.5451039570757881, 0.5667961701879984, 0.5523532991231132, None)\n",
      "(0.5488721804511278, 0.5488721804511278, 0.5488721804511278, None)\n",
      "(0.5404349083794175, 0.5488721804511278, 0.5409789348753004, None)\n",
      "0.39843956126795066\n"
     ]
    }
   ],
   "source": [
    "#Initialise vectoriser\n",
    "count_vectorizer = CountVectorizer()\n",
    "clf = LogisticRegression()\n",
    "target_names = [str(i) for i in sorted(y.unique())] #Convert to string\n",
    "\n",
    "\n",
    "# data is an array with our already pre-processed dataset examples\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    print(\"Train:\", len(train_index), \"Test:\", len(test_index))\n",
    "    X_train, X_test = X.reindex(train_index), X.reindex(test_index)\n",
    "    y_train, y_test = y.reindex(train_index), y.reindex(test_index)\n",
    "    \n",
    "    #Make pipeline to train classifier\n",
    "    pipe = make_pipeline(count_vectorizer, clf)\n",
    "    pipe.fit(X_train['EssayText'], y_train)\n",
    "    \n",
    "    #Make predictions on test data\n",
    "    y_pred = pipe.predict(X_test['EssayText'])\n",
    "    \n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='macro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='micro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='weighted'))\n",
    "    print(cohen_kappa_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1339, 1) (1339,)\n",
      "Train: 1069 Test: 270\n",
      "(0.4535262298428251, 0.4392591015541835, 0.4329341058694658, None)\n",
      "(0.44814814814814813, 0.44814814814814813, 0.44814814814814813, None)\n",
      "(0.44540888919129373, 0.44814814814814813, 0.43417279772617495, None)\n",
      "0.24774210437741917\n",
      "Train: 1070 Test: 269\n",
      "(0.3831232492997199, 0.3890151515151515, 0.38478021978021976, None)\n",
      "(0.3940520446096654, 0.3940520446096654, 0.3940520446096654, None)\n",
      "(0.386872221007362, 0.3940520446096654, 0.3891923689693206, None)\n",
      "0.1832845940358001\n",
      "Train: 1071 Test: 268\n",
      "(0.42422500425821835, 0.41681792103478854, 0.4096899819898355, None)\n",
      "(0.4291044776119403, 0.4291044776119403, 0.4291044776119403, None)\n",
      "(0.4235424182104297, 0.4291044776119403, 0.4164891921006229, None)\n",
      "0.2258283772302463\n",
      "Train: 1073 Test: 266\n",
      "(0.4558498399359744, 0.46317904468114, 0.4547386851944863, None)\n",
      "(0.46616541353383456, 0.46616541353383456, 0.46616541353383456, None)\n",
      "(0.45407817262243244, 0.46616541353383456, 0.45534104598512853, None)\n",
      "0.27851317020992117\n",
      "Train: 1073 Test: 266\n",
      "(0.4527128427128427, 0.4645752090487554, 0.4433417023580958, None)\n",
      "(0.46616541353383456, 0.46616541353383456, 0.46616541353383456, None)\n",
      "(0.4493721316277707, 0.46616541353383456, 0.44332097412339, None)\n",
      "0.27825123246837624\n"
     ]
    }
   ],
   "source": [
    "X = set_1[['function_based_text','Score1']].copy()\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "y= X.pop('Score1')\n",
    "\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "#Initialise vectoriser\n",
    "count_vectorizer = CountVectorizer()\n",
    "clf = LogisticRegression() #OvR classifier\n",
    "target_names = [str(i) for i in sorted(y.unique())] #Convert to string\n",
    "\n",
    "\n",
    "# data is an array with our already pre-processed dataset examples\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    print(\"Train:\", len(train_index), \"Test:\", len(test_index))\n",
    "    X_train, X_test = X.reindex(train_index), X.reindex(test_index)\n",
    "    y_train, y_test = y.reindex(train_index), y.reindex(test_index)\n",
    "    \n",
    "    #Make pipeline to train classifier\n",
    "    pipe = make_pipeline(count_vectorizer, clf)\n",
    "    pipe.fit(X_train['function_based_text'], y_train)\n",
    "    \n",
    "    #Make predictions on test data\n",
    "    y_pred = pipe.predict(X_test['function_based_text'])\n",
    "    \n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='macro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='micro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='weighted'))\n",
    "    print(cohen_kappa_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise vectoriser\n",
    "count_vectorizer = CountVectorizer()\n",
    "clf = LogisticRegression() #OvR classifier\n",
    "target_names = [str(i) for i in sorted(y.unique())] #Convert to string\n",
    "\n",
    "\n",
    "# data is an array with our already pre-processed dataset examples\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    \n",
    "    print(\"Train:\", len(train_index), \"Test:\", len(test_index))\n",
    "    X_train, X_test = X.reindex(train_index), X.reindex(test_index)\n",
    "    y_train, y_test = y.reindex(train_index), y.reindex(test_index)\n",
    "    \n",
    "    #Make pipeline to train classifier\n",
    "    pipe = make_pipeline(count_vectorizer, clf)\n",
    "    pipe.fit(X_train['EssayText'], y_train)\n",
    "    \n",
    "    #Make predictions on test data\n",
    "    y_pred = pipe.predict(X_test['EssayText'])\n",
    "    \n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='macro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='micro'))\n",
    "    print(precision_recall_fscore_support(y_test, y_pred, average='weighted'))\n",
    "    print(cohen_kappa_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Features\n",
    "* custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* N-grams (words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* n-grams (POS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenate Features & Prepare X & Y "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare X & Y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.SparseDataFrame(data=merged_2, columns=feature_names)\n",
    "X_train.head()\n",
    "\n",
    "#X_train = csr_matrix(merged_2) \n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1170,)\n"
     ]
    }
   ],
   "source": [
    "#y_train_tmp = pd.DataFrame(y_train_tmp)\n",
    "# y_train_scaled = StandardScaler().fit_transform(y_train_tmp.astype(float))\n",
    "# y_train_scaled = pd.DataFrame(y_train_scaled, index=y_train_tmp.index, columns=['Score1'])\n",
    "# y_train = np.squeeze(y_train_scaled)\n",
    "\n",
    "\n",
    "y_train = y_train_tmp\n",
    "\n",
    "#print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1170, 264)\n"
     ]
    }
   ],
   "source": [
    "print(text_ngrams_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFICATION\n",
    "## Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\stylistics\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectFromModel, SelectKBest, f_classif, mutual_info_classif\n",
    "#from sklearn.linear_model import Lasso\n",
    "#from sklearn.ensemble import ExtraTreesRegressor, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "\n",
    "import eli5\n",
    "from eli5.lime import TextExplainer\n",
    "\n",
    "from yellowbrick.features.importances import FeatureImportances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Univariate Selection\n",
    "* Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "kBestmodel = SelectKBest(mutual_info_classif, k='all')\n",
    "fit_data = kBestmodel.fit(text_ngrams_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>kBest_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>__VERB__</td>\n",
       "      <td>0.087464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>__NOUN__</td>\n",
       "      <td>0.078108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>to</td>\n",
       "      <td>0.070309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>__ADV__</td>\n",
       "      <td>0.057497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>of</td>\n",
       "      <td>0.052992</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  kBest_weight\n",
       "108  __VERB__  0.087464    \n",
       "106  __NOUN__  0.078108    \n",
       "238  to        0.070309    \n",
       "105  __ADV__   0.057497    \n",
       "191  of        0.052992    "
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance = list(zip(text_ngrams_columns, fit_data.scores_))\n",
    "kBest_feature_importance = pd.DataFrame(feature_importance, columns=['feature','kBest_weight'])\n",
    "kBest_feature_importance.sort_values(by='kBest_weight', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>kBest_weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>zero</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>inside</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>it</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>materialinto</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>me</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>60minsand</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>no</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>4s</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          feature  kBest_weight\n",
       "263  zero          0.0         \n",
       "176  inside        0.0         \n",
       "178  it            0.0         \n",
       "92   8             0.0         \n",
       "181  materialinto  0.0         \n",
       "182  me            0.0         \n",
       "87   60minsand     0.0         \n",
       "188  no            0.0         \n",
       "84   5             0.0         \n",
       "83   4s            0.0         "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kBest_feature_importance.sort_values(by='kBest_weight').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Baseline Model\n",
    "* Logitistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_report(pipe, X, y, target_names):\n",
    "    y_test = y\n",
    "    y_pred = pipe.predict(X)\n",
    "    report = metrics.classification_report(y_test, y_pred, target_names=target_names)\n",
    "    print(report)\n",
    "    print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "  ...2', random_state=None,\n",
       "           refit=True, scoring=None, solver='lbfgs', tol=0.0001, verbose=0))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We’re using LogisticRegressionCV here to adjust regularization parameter C automatically. \n",
    "# It allows to compare different vectorizers - optimal C value could be different for different input features \n",
    "# (e.g. for bigrams or for character-level input).\n",
    "# An alternative would be to use GridSearchCV or RandomizedSearchCV.\n",
    "\n",
    "\n",
    "#Initialise vectoriser\n",
    "count_vectorizer = CountVectorizer()\n",
    "clf = LogisticRegressionCV()\n",
    "target_names = [str(i) for i in sorted(y_train_tmp.unique())] #Convert to string\n",
    "\n",
    "pipe = make_pipeline(count_vectorizer, clf)\n",
    "pipe.fit(train['EssayText'], y_train_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.95      0.83       268\n",
      "          1       0.94      0.43      0.59       309\n",
      "          2       0.84      0.97      0.90       593\n",
      "\n",
      "avg / total       0.84      0.82      0.80      1170\n",
      "\n",
      "accuracy: 0.824\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.89      0.84       112\n",
      "          1       0.71      0.30      0.42       120\n",
      "          2       0.78      0.94      0.85       270\n",
      "\n",
      "avg / total       0.76      0.77      0.75       502\n",
      "\n",
      "accuracy: 0.775\n"
     ]
    }
   ],
   "source": [
    "print_report(pipe,train['EssayText'], y_train_tmp, target_names)\n",
    "\n",
    "print_report(pipe,test['EssayText'], y_test_tmp, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights-wrapper\" style=\"border-collapse: collapse; border: none; margin-bottom: 1.5em;\">\n",
       "            <tr>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "                    <td style=\"padding: 0.5em; border: 1px solid black; text-align: center;\">\n",
       "                        <b>\n",
       "    \n",
       "        y=2\n",
       "    \n",
       "</b>\n",
       "\n",
       "top features\n",
       "                    </td>\n",
       "                \n",
       "            </tr>\n",
       "            <tr>\n",
       "                \n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.19%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.191\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.77%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.422\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        mass\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.22%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.266\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        it\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.28%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.260\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        will\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.45%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.243\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        then\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.63%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.226\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        them\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 96.63%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 682 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.56%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 1240 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.232\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        size\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 96.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.269\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        temperature\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.75%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.314\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        are\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 95.18%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.376\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        what\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 94.21%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.489\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        amount\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.74%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.546\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        used\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.32%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.599\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        how\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 93.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.640\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        much\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.76%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.671\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        vinegar\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        is\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.82%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        they\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        you\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 99.83%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 685 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.85%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 1237 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        size\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        would\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        should\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        the\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        what\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        need\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.83%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.003\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        containers\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.80%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        be\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        samples\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        container\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.79%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.004\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        know\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.56%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.982\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                        <td style=\"padding: 0px; border: 1px solid black; vertical-align: top;\">\n",
       "                            \n",
       "                                \n",
       "                                    \n",
       "                                    \n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; width: 100%;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature weights. Note that weights do not account for feature value scales, so if feature values have different scales, features with highest weights might not be the most important.\">\n",
       "                    Weight<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 87.10%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.533\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        size\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 89.16%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.196\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        long\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.065\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        temperature\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.14%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.044\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        where\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.42%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.002\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        type\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.64%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.969\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        big\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.91%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.930\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        kind\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.03%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.913\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        vinegar\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.51%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.844\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        container\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 91.84%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.797\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        rinse\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.53%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.702\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        must\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 92.53%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 920 more positive &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.25%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 1002 more negative &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 92.25%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.740\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        hypothesis\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.69%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.818\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        many\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.917\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        from\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.869\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "                                \n",
       "                            \n",
       "                        </td>\n",
       "                    \n",
       "                \n",
       "            </tr>\n",
       "        </table>\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Intercept (bias) feature is shown as <BIAS> in the same table. \n",
    "#We can inspect features and weights because we’re using a bag-of-words vectorizer and a linear classifier\n",
    "#(so there is a direct mapping between individual words and classifier coefficients)\n",
    "\n",
    "#eli5.show_weights(clf, top=10)\n",
    "eli5.show_weights(clf, vec=count_vectorizer, top=15,  target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.126</b>, score <b>-2.409</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.78%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.191\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -3.600\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 87.36%); opacity: 0.84\" title=\"-0.176\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.16%); opacity: 0.81\" title=\"-0.032\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.57%); opacity: 0.82\" title=\"0.099\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.06%); opacity: 0.82\" title=\"0.075\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.96%); opacity: 0.83\" title=\"-0.145\">additional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.93%); opacity: 0.80\" title=\"-0.005\">iformation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.73%); opacity: 0.82\" title=\"-0.113\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.29%); opacity: 0.80\" title=\"-0.010\">perform</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.54%); opacity: 0.81\" title=\"-0.067\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.57%); opacity: 0.82\" title=\"0.099\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.13%); opacity: 0.81\" title=\"-0.059\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.06%); opacity: 0.81\" title=\"-0.060\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.42%); opacity: 0.80\" title=\"0.002\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.54%); opacity: 0.81\" title=\"-0.067\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.16%); opacity: 0.91\" title=\"-0.489\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.33%); opacity: 0.83\" title=\"-0.157\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 67.74%); opacity: 0.95\" title=\"-0.671\">vinegar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.97%); opacity: 0.84\" title=\"-0.164\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.38%); opacity: 0.83\" title=\"-0.156\">poured</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.62%); opacity: 0.82\" title=\"-0.082\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.54%); opacity: 0.81\" title=\"-0.067\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.79%); opacity: 0.83\" title=\"-0.148\">container</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 96.16%); opacity: 0.81\" title=\"-0.032\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.53%); opacity: 0.81\" title=\"0.028\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.03%); opacity: 0.82\" title=\"0.108\">effect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.54%); opacity: 0.81\" title=\"-0.067\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.16%); opacity: 0.91\" title=\"-0.489\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.33%); opacity: 0.83\" title=\"-0.157\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.68%); opacity: 0.89\" title=\"0.422\">mass</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.87%); opacity: 0.81\" title=\"-0.024\">lost</span><span style=\"opacity: 0.80\"> fom </span><span style=\"background-color: hsl(0, 100.00%, 93.54%); opacity: 0.81\" title=\"-0.067\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.35%); opacity: 0.84\" title=\"-0.176\">samples</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 92.16%); opacity: 0.82\" title=\"-0.089\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.65%); opacity: 0.84\" title=\"0.170\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.86%); opacity: 0.81\" title=\"0.036\">placing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.97%); opacity: 0.85\" title=\"0.226\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.36%); opacity: 0.84\" title=\"-0.176\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.64%); opacity: 0.80\" title=\"0.016\">certain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.52%); opacity: 0.80\" title=\"0.017\">places</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.35%); opacity: 0.83\" title=\"0.157\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.51%); opacity: 0.80\" title=\"-0.002\">different</span><span style=\"opacity: 0.80\"> temparatures </span><span style=\"background-color: hsl(120, 100.00%, 97.72%); opacity: 0.80\" title=\"0.015\">effects</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 70.23%); opacity: 0.93\" title=\"-0.599\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.80%); opacity: 0.94\" title=\"-0.640\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.54%); opacity: 0.81\" title=\"-0.067\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.35%); opacity: 0.84\" title=\"-0.176\">samples</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.13%); opacity: 0.81\" title=\"-0.059\">would</span><span style=\"opacity: 0.80\"> loose </span><span style=\"background-color: hsl(120, 100.00%, 76.68%); opacity: 0.89\" title=\"0.422\">mass</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.404</b>, score <b>-1.027</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 99.07%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.045\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 91.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.982\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 99.61%); opacity: 0.80\" title=\"-0.001\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.71%); opacity: 0.80\" title=\"0.001\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.94%); opacity: 0.80\" title=\"-0.000\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.91%); opacity: 0.80\" title=\"0.000\">additional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.95%); opacity: 0.80\" title=\"0.000\">iformation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.54%); opacity: 0.80\" title=\"-0.002\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.92%); opacity: 0.80\" title=\"0.000\">perform</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.25%); opacity: 0.80\" title=\"-0.003\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.69%); opacity: 0.80\" title=\"0.001\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.30%); opacity: 0.80\" title=\"-0.003\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.11%); opacity: 0.80\" title=\"-0.004\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.67%); opacity: 0.80\" title=\"0.001\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.25%); opacity: 0.80\" title=\"-0.003\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.68%); opacity: 0.80\" title=\"0.001\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.32%); opacity: 0.80\" title=\"-0.003\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.54%); opacity: 0.80\" title=\"-0.002\">vinegar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.19%); opacity: 0.80\" title=\"0.003\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.87%); opacity: 0.80\" title=\"0.000\">poured</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.82%); opacity: 0.80\" title=\"-0.000\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.25%); opacity: 0.80\" title=\"-0.003\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.07%); opacity: 0.80\" title=\"-0.004\">container</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 99.71%); opacity: 0.80\" title=\"0.001\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.79%); opacity: 0.80\" title=\"0.000\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.83%); opacity: 0.80\" title=\"-0.000\">effect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.25%); opacity: 0.80\" title=\"-0.003\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.68%); opacity: 0.80\" title=\"0.001\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.32%); opacity: 0.80\" title=\"-0.003\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.86%); opacity: 0.80\" title=\"-0.000\">mass</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.84%); opacity: 0.80\" title=\"0.000\">lost</span><span style=\"opacity: 0.80\"> fom </span><span style=\"background-color: hsl(0, 100.00%, 99.25%); opacity: 0.80\" title=\"-0.003\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.09%); opacity: 0.80\" title=\"-0.004\">samples</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(0, 100.00%, 99.52%); opacity: 0.80\" title=\"-0.002\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.87%); opacity: 0.80\" title=\"-0.000\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.91%); opacity: 0.80\" title=\"-0.000\">placing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.69%); opacity: 0.80\" title=\"-0.001\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.61%); opacity: 0.80\" title=\"-0.001\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.92%); opacity: 0.80\" title=\"0.000\">certain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.97%); opacity: 0.80\" title=\"-0.000\">places</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.85%); opacity: 0.80\" title=\"-0.000\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.97%); opacity: 0.80\" title=\"-0.000\">different</span><span style=\"opacity: 0.80\"> temparatures </span><span style=\"background-color: hsl(0, 100.00%, 99.96%); opacity: 0.80\" title=\"-0.000\">effects</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.96%); opacity: 0.80\" title=\"-0.000\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.86%); opacity: 0.80\" title=\"0.000\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.25%); opacity: 0.80\" title=\"-0.003\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.09%); opacity: 0.80\" title=\"-0.004\">samples</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.30%); opacity: 0.80\" title=\"-0.003\">would</span><span style=\"opacity: 0.80\"> loose </span><span style=\"background-color: hsl(0, 100.00%, 99.86%); opacity: 0.80\" title=\"-0.000\">mass</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=2\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.470</b>, score <b>-0.814</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 86.49%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +2.055\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 82.94%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -2.869\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 98.25%); opacity: 0.80\" title=\"0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.40%); opacity: 0.84\" title=\"0.195\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.81%); opacity: 0.81\" title=\"-0.049\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.98%); opacity: 0.81\" title=\"-0.047\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.46%); opacity: 0.85\" title=\"0.236\">additional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.67%); opacity: 0.81\" title=\"-0.038\">iformation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.00%); opacity: 0.83\" title=\"-0.126\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.65%); opacity: 0.81\" title=\"0.038\">perform</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.50%); opacity: 0.81\" title=\"0.068\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.81%); opacity: 0.81\" title=\"-0.049\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.56%); opacity: 0.83\" title=\"-0.116\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.43%); opacity: 0.86\" title=\"0.282\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.99%); opacity: 0.83\" title=\"-0.126\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.50%); opacity: 0.81\" title=\"0.068\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.38%); opacity: 0.85\" title=\"0.238\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.68%); opacity: 0.80\" title=\"-0.016\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 60.00%); opacity: 1.00\" title=\"0.913\">vinegar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.49%); opacity: 0.86\" title=\"-0.258\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.73%); opacity: 0.82\" title=\"0.080\">poured</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.31%); opacity: 0.82\" title=\"-0.087\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.50%); opacity: 0.81\" title=\"0.068\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 62.14%); opacity: 0.98\" title=\"0.844\">container</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 86.40%); opacity: 0.84\" title=\"0.195\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.75%); opacity: 0.90\" title=\"-0.473\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.14%); opacity: 0.89\" title=\"0.410\">effect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.50%); opacity: 0.81\" title=\"0.068\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.38%); opacity: 0.85\" title=\"0.238\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.68%); opacity: 0.80\" title=\"-0.016\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 73.82%); opacity: 0.91\" title=\"-0.498\">mass</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.48%); opacity: 0.85\" title=\"-0.236\">lost</span><span style=\"opacity: 0.80\"> fom </span><span style=\"background-color: hsl(120, 100.00%, 93.50%); opacity: 0.81\" title=\"0.068\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.68%); opacity: 0.91\" title=\"0.502\">samples</span><span style=\"opacity: 0.80\">. i </span><span style=\"background-color: hsl(120, 100.00%, 88.96%); opacity: 0.83\" title=\"0.145\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.19%); opacity: 0.84\" title=\"-0.200\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.09%); opacity: 0.81\" title=\"-0.033\">placing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.67%); opacity: 0.83\" title=\"-0.114\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.25%); opacity: 0.80\" title=\"0.010\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.76%); opacity: 0.85\" title=\"-0.209\">certain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.74%); opacity: 0.81\" title=\"-0.037\">places</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.43%); opacity: 0.84\" title=\"-0.175\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.75%); opacity: 0.80\" title=\"0.006\">different</span><span style=\"opacity: 0.80\"> temparatures </span><span style=\"background-color: hsl(0, 100.00%, 96.82%); opacity: 0.81\" title=\"-0.024\">effects</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 90.27%); opacity: 0.83\" title=\"0.121\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.27%); opacity: 0.85\" title=\"0.219\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.50%); opacity: 0.81\" title=\"0.068\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 73.68%); opacity: 0.91\" title=\"0.502\">samples</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.56%); opacity: 0.83\" title=\"-0.116\">would</span><span style=\"opacity: 0.80\"> loose </span><span style=\"background-color: hsl(0, 100.00%, 73.82%); opacity: 0.91\" title=\"-0.498\">mass</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_prediction(clf, test['EssayText'][438], vec=count_vectorizer, target_names=target_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def test_print_report(pipe):\n",
    "#     y_test = y_test_tmp\n",
    "#     y_pred = pipe.predict(test['EssayText'])\n",
    "#     report = metrics.classification_report(y_test, y_pred,\n",
    "#         target_names=target_names)\n",
    "#     print(report)\n",
    "#     print(\"accuracy: {:0.3f}\".format(metrics.accuracy_score(y_test, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise vectoriser\n",
    "clf = MultinomialNB()\n",
    "pipe = make_pipeline(count_vectorizer, clf)\n",
    "pipe.fit(train['EssayText'], y_train_tmp);\n",
    "#MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.75      0.84       268\n",
      "          1       0.81      0.58      0.68       309\n",
      "          2       0.78      0.97      0.87       593\n",
      "\n",
      "avg / total       0.83      0.82      0.81      1170\n",
      "\n",
      "accuracy: 0.819\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.50      0.63       112\n",
      "          1       0.42      0.23      0.30       120\n",
      "          2       0.70      0.96      0.81       270\n",
      "\n",
      "avg / total       0.67      0.68      0.65       502\n",
      "\n",
      "accuracy: 0.681\n"
     ]
    }
   ],
   "source": [
    "print_report(pipe,train['EssayText'], y_train_tmp, target_names)\n",
    "\n",
    "print_report(pipe,test['EssayText'], y_test_tmp, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_top10(vectorizer, clf, class_labels):\n",
    "    \"\"\"Prints features with the highest coefficient values, per class\"\"\"\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    for i, class_label in enumerate(class_labels):\n",
    "        top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "        print(\"%s: %s\" % (class_label, \" \".join(feature_names[j] for j in top10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: experiment in would need mass of you and to the\n",
      "1: and experiment how you in need would of to the\n",
      "2: what vinegar know how in need would of to the\n"
     ]
    }
   ],
   "source": [
    "print_top10(count_vectorizer, clf, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t-9.2963\t100            \t\t-2.6005\tthe            \n",
      "\t-9.2963\t100g           \t\t-3.1849\tto             \n",
      "\t-9.2963\t100ml          \t\t-3.7590\tand            \n",
      "\t-9.2963\t10cm           \t\t-3.8847\tyou            \n",
      "\t-9.2963\t10g            \t\t-3.8847\tof             \n",
      "\t-9.2963\t11grams        \t\t-3.9118\tmass           \n",
      "\t-9.2963\t1day           \t\t-3.9350\tneed           \n",
      "\t-9.2963\t1st            \t\t-3.9980\twould          \n",
      "\t-9.2963\t1telling       \t\t-4.0285\tin             \n",
      "\t-9.2963\t2days          \t\t-4.2725\texperiment     \n",
      "\t-9.2963\t30min          \t\t-4.4923\tsamples        \n",
      "\t-9.2963\t3rd            \t\t-4.5601\tthey           \n",
      "\t-9.2963\t50g            \t\t-4.6142\tit             \n",
      "\t-9.2963\t6th            \t\t-4.6424\tis             \n",
      "\t-9.2963\t7grams         \t\t-4.7320\tfor            \n",
      "\t-9.2963\tabove          \t\t-4.7530\twhat           \n",
      "\t-9.2963\tabsolutely     \t\t-4.7745\tsample         \n",
      "\t-9.2963\tabsorb         \t\t-4.7965\teach           \n",
      "\t-9.2963\tabsorbed       \t\t-4.8304\tinformation    \n",
      "\t-9.2963\taccuracy       \t\t-4.8420\tthis           \n"
     ]
    }
   ],
   "source": [
    "# It means that higher values mean more important features for the positive class.\n",
    "# The above print shows the top 20 lowest values (less predictive features) in the first column \n",
    "#and the top 20 high values (highest predictive features) in the second column.\n",
    "\n",
    "def show_most_informative_features(vectorizer, clf, n=20):\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    coefs_with_fns = sorted(zip(clf.coef_[0], feature_names))\n",
    "    top = zip(coefs_with_fns[:n], coefs_with_fns[:-(n + 1):-1])\n",
    "    for (coef_1, fn_1), (coef_2, fn_2) in top:\n",
    "        print(\"\\t%.4f\\t%-15s\\t\\t%.4f\\t%-15s\" % (coef_1, fn_1, coef_2, fn_2))\n",
    "        \n",
    "show_most_informative_features(count_vectorizer, clf, n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialise vectoriser\n",
    "clf = BernoulliNB()\n",
    "pipe = make_pipeline(count_vectorizer, clf)\n",
    "pipe.fit(train['EssayText'], y_train);\n",
    "#MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.61      0.63       268\n",
      "          1       0.53      0.27      0.36       309\n",
      "          2       0.68      0.86      0.76       593\n",
      "\n",
      "avg / total       0.63      0.65      0.62      1170\n",
      "\n",
      "accuracy: 0.649\n"
     ]
    }
   ],
   "source": [
    "print_report(pipe,train['EssayText'], y_train, target_names)\n",
    "\n",
    "print_report(pipe,test['EssayText'], y_test_tmp, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.63      0.55      0.59       112\n",
      "          1       0.41      0.16      0.23       120\n",
      "          2       0.65      0.86      0.74       270\n",
      "\n",
      "avg / total       0.59      0.63      0.59       502\n",
      "\n",
      "accuracy: 0.625\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('countvectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "  ...',\n",
       "  max_iter=-1, probability=True, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False))])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#clf = svm.SVC(gamma='scale', decision_function_shape='ovo')\n",
    "clf = SVC(kernel='linear', probability=True)\n",
    "pipe = make_pipeline(count_vectorizer, clf)\n",
    "pipe.fit(train['EssayText'], y_train_tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98       268\n",
      "          1       0.99      0.97      0.98       309\n",
      "          2       0.99      0.98      0.98       593\n",
      "\n",
      "avg / total       0.98      0.98      0.98      1170\n",
      "\n",
      "accuracy: 0.982\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.71      0.71       112\n",
      "          1       0.46      0.49      0.48       120\n",
      "          2       0.81      0.79      0.80       270\n",
      "\n",
      "avg / total       0.70      0.70      0.70       502\n",
      "\n",
      "accuracy: 0.699\n"
     ]
    }
   ],
   "source": [
    "print_report(pipe,train['EssayText'], y_train_tmp, target_names)\n",
    "\n",
    "print_report(pipe,test['EssayText'], y_test_tmp, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=0\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.290</b>, score <b>-0.712</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 94.85%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +0.163\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 83.34%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.875\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 95.29%); opacity: 0.81\" title=\"-0.038\">in</span><span style=\"opacity: 0.80\"> this </span><span style=\"background-color: hsl(120, 100.00%, 97.64%); opacity: 0.80\" title=\"0.014\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 75.20%); opacity: 0.90\" title=\"0.410\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.49%); opacity: 0.87\" title=\"-0.291\">additional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.07%); opacity: 0.81\" title=\"-0.029\">iformation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.66%); opacity: 0.82\" title=\"-0.086\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 97.65%); opacity: 0.80\" title=\"0.014\">perform</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.86%); opacity: 0.81\" title=\"0.056\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.86%); opacity: 0.81\" title=\"0.056\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.37%); opacity: 0.85\" title=\"0.193\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.74%); opacity: 0.85\" title=\"-0.205\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.46%); opacity: 0.80\" title=\"-0.016\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.90%); opacity: 0.81\" title=\"0.021\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 66.09%); opacity: 0.96\" title=\"-0.641\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.03%); opacity: 0.80\" title=\"-0.020\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 74.90%); opacity: 0.90\" title=\"-0.417\">vinegar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.90%); opacity: 0.81\" title=\"0.055\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.60%); opacity: 0.86\" title=\"-0.227\">poured</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 83.91%); opacity: 0.85\" title=\"0.221\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.15%); opacity: 0.82\" title=\"-0.065\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.41%); opacity: 0.88\" title=\"-0.314\">container</span><span style=\"opacity: 0.80\">. this </span><span style=\"background-color: hsl(120, 100.00%, 77.81%); opacity: 0.89\" title=\"0.350\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.79%); opacity: 0.85\" title=\"0.185\">effect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.75%); opacity: 0.81\" title=\"-0.057\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 66.09%); opacity: 0.96\" title=\"-0.641\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.03%); opacity: 0.80\" title=\"-0.020\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 79.68%); opacity: 0.88\" title=\"0.308\">mass</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.90%); opacity: 0.81\" title=\"-0.031\">lost</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.53%); opacity: 0.80\" title=\"0.007\">fom</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.49%); opacity: 0.81\" title=\"-0.036\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.81%); opacity: 0.86\" title=\"-0.243\">samples</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 92.51%); opacity: 0.82\" title=\"-0.074\">i</span><span style=\"opacity: 0.80\"> also </span><span style=\"background-color: hsl(120, 100.00%, 74.16%); opacity: 0.91\" title=\"0.435\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.96%); opacity: 0.83\" title=\"0.129\">placing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 69.68%); opacity: 0.93\" title=\"0.546\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.46%); opacity: 0.81\" title=\"0.025\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.49%); opacity: 0.84\" title=\"0.154\">certain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.52%); opacity: 0.87\" title=\"0.269\">places</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.02%); opacity: 0.81\" title=\"0.041\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 87.96%); opacity: 0.84\" title=\"-0.146\">different</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.56%); opacity: 0.80\" title=\"-0.007\">temparatures</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.46%); opacity: 0.80\" title=\"-0.008\">effects</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.32%); opacity: 0.87\" title=\"-0.295\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 60.00%); opacity: 1.00\" title=\"-0.811\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.49%); opacity: 0.81\" title=\"-0.036\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.68%); opacity: 0.84\" title=\"-0.169\">samples</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 85.37%); opacity: 0.85\" title=\"0.193\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.54%); opacity: 0.80\" title=\"-0.015\">loose</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.38%); opacity: 0.87\" title=\"0.293\">mass</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=1\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.175</b>, score <b>-1.396</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 90.61%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.386\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 81.57%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -1.011\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(0, 100.00%, 91.88%); opacity: 0.82\" title=\"-0.083\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.72%); opacity: 0.81\" title=\"-0.023\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 99.10%); opacity: 0.80\" title=\"-0.004\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.76%); opacity: 0.83\" title=\"-0.132\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.08%); opacity: 0.82\" title=\"0.095\">additional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.14%); opacity: 0.80\" title=\"-0.010\">iformation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.19%); opacity: 0.81\" title=\"0.039\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.44%); opacity: 0.82\" title=\"-0.090\">perform</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.50%); opacity: 0.82\" title=\"-0.089\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.60%); opacity: 0.81\" title=\"-0.046\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.86%); opacity: 0.82\" title=\"0.069\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.96%); opacity: 0.82\" title=\"-0.082\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 88.32%); opacity: 0.83\" title=\"0.140\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.02%); opacity: 0.80\" title=\"0.011\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.12%); opacity: 0.87\" title=\"0.299\">amount</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 96.12%); opacity: 0.81\" title=\"0.029\">vinegar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.29%); opacity: 0.83\" title=\"0.124\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.14%); opacity: 0.81\" title=\"-0.040\">poured</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.11%); opacity: 0.82\" title=\"0.066\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.11%); opacity: 0.82\" title=\"0.066\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.71%); opacity: 0.86\" title=\"-0.225\">container</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 93.89%); opacity: 0.81\" title=\"-0.055\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.99%); opacity: 0.80\" title=\"0.020\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 68.42%); opacity: 0.94\" title=\"-0.579\">effect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 99.00%); opacity: 0.80\" title=\"0.004\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.12%); opacity: 0.87\" title=\"0.299\">amount</span><span style=\"opacity: 0.80\"> of </span><span style=\"background-color: hsl(120, 100.00%, 93.21%); opacity: 0.82\" title=\"0.064\">mass</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.96%); opacity: 0.85\" title=\"0.201\">lost</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.34%); opacity: 0.82\" title=\"0.063\">fom</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.85%); opacity: 0.81\" title=\"0.043\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.98%); opacity: 0.82\" title=\"-0.082\">samples</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 93.13%); opacity: 0.82\" title=\"0.065\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.55%); opacity: 0.81\" title=\"-0.024\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 83.64%); opacity: 0.86\" title=\"-0.226\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 90.04%); opacity: 0.83\" title=\"-0.111\">placing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 85.05%); opacity: 0.85\" title=\"-0.199\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 94.53%); opacity: 0.81\" title=\"-0.047\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.92%); opacity: 0.80\" title=\"0.005\">certain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.74%); opacity: 0.84\" title=\"-0.168\">places</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.47%); opacity: 0.82\" title=\"-0.089\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.16%); opacity: 0.84\" title=\"0.178\">different</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.43%); opacity: 0.81\" title=\"0.049\">temparatures</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.12%); opacity: 0.81\" title=\"0.040\">effects</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.13%); opacity: 0.84\" title=\"0.161\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.31%); opacity: 0.87\" title=\"0.274\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 96.69%); opacity: 0.81\" title=\"0.023\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 89.74%); opacity: 0.83\" title=\"-0.116\">samples</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.34%); opacity: 0.82\" title=\"0.063\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.42%); opacity: 0.82\" title=\"0.062\">loose</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.99%); opacity: 0.81\" title=\"0.042\">mass</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "        \n",
       "    \n",
       "        \n",
       "        \n",
       "    \n",
       "        <p style=\"margin-bottom: 0.5em; margin-top: 0em\">\n",
       "            <b>\n",
       "    \n",
       "        y=2\n",
       "    \n",
       "</b>\n",
       "\n",
       "    \n",
       "    (probability <b>0.535</b>, score <b>0.435</b>)\n",
       "\n",
       "top features\n",
       "        </p>\n",
       "    \n",
       "    <table class=\"eli5-weights\"\n",
       "           style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto; margin-bottom: 2em;\">\n",
       "        <thead>\n",
       "        <tr style=\"border: none;\">\n",
       "            \n",
       "                <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\" title=\"Feature contribution already accounts for the feature value (for linear models, contribution = weight * feature value), and the sum of feature contributions is equal to the score or, for some classifiers, to the probability. Feature values are shown if &quot;show_feature_values&quot; is True.\">\n",
       "                    Contribution<sup>?</sup>\n",
       "                </th>\n",
       "            \n",
       "            <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "            \n",
       "        </tr>\n",
       "        </thead>\n",
       "        <tbody>\n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        +1.136\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        Highlighted in text (sum)\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "        \n",
       "\n",
       "        \n",
       "        \n",
       "            <tr style=\"background-color: hsl(0, 100.00%, 85.74%); border: none;\">\n",
       "    <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "        -0.701\n",
       "    </td>\n",
       "    <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "        &lt;BIAS&gt;\n",
       "    </td>\n",
       "    \n",
       "</tr>\n",
       "        \n",
       "\n",
       "        </tbody>\n",
       "    </table>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n",
       "    <p style=\"margin-bottom: 2.5em; margin-top:-0.5em;\">\n",
       "        <span style=\"background-color: hsl(120, 100.00%, 86.08%); opacity: 0.84\" title=\"0.180\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.52%); opacity: 0.81\" title=\"0.047\">this</span><span style=\"opacity: 0.80\"> experiment </span><span style=\"background-color: hsl(0, 100.00%, 79.90%); opacity: 0.87\" title=\"-0.304\">an</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 84.76%); opacity: 0.85\" title=\"0.204\">additional</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.34%); opacity: 0.83\" title=\"0.123\">iformation</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.17%); opacity: 0.82\" title=\"0.094\">to</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.23%); opacity: 0.81\" title=\"0.039\">perform</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.59%); opacity: 0.81\" title=\"0.047\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 95.52%); opacity: 0.81\" title=\"0.036\">experiment</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 88.73%); opacity: 0.83\" title=\"-0.133\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.16%); opacity: 0.88\" title=\"0.342\">be</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 96.16%); opacity: 0.81\" title=\"-0.029\">that</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.84%); opacity: 0.82\" title=\"0.084\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.41%); opacity: 0.88\" title=\"0.336\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 98.05%); opacity: 0.80\" title=\"0.011\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 67.07%); opacity: 0.95\" title=\"0.615\">vinegar</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 93.78%); opacity: 0.81\" title=\"-0.057\">is</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 77.01%); opacity: 0.89\" title=\"0.368\">poured</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 82.84%); opacity: 0.86\" title=\"-0.242\">into</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 89.87%); opacity: 0.83\" title=\"0.114\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 65.86%); opacity: 0.96\" title=\"0.647\">container</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(120, 100.00%, 90.82%); opacity: 0.82\" title=\"0.099\">this</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.97%); opacity: 0.87\" title=\"-0.281\">may</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 76.25%); opacity: 0.89\" title=\"0.385\">effect</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 87.13%); opacity: 0.84\" title=\"0.161\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 78.41%); opacity: 0.88\" title=\"0.336\">amount</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 98.80%); opacity: 0.80\" title=\"-0.005\">of</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.71%); opacity: 0.87\" title=\"-0.286\">mass</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 92.55%); opacity: 0.82\" title=\"-0.074\">lost</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.34%); opacity: 0.82\" title=\"0.063\">fom</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 93.12%); opacity: 0.82\" title=\"0.066\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 80.94%); opacity: 0.87\" title=\"0.281\">samples</span><span style=\"opacity: 0.80\">. </span><span style=\"background-color: hsl(0, 100.00%, 98.69%); opacity: 0.80\" title=\"-0.006\">i</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.32%); opacity: 0.82\" title=\"0.091\">also</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.87%); opacity: 0.85\" title=\"-0.202\">think</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 95.26%); opacity: 0.81\" title=\"-0.039\">placing</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 80.67%); opacity: 0.87\" title=\"-0.287\">them</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 86.97%); opacity: 0.84\" title=\"0.163\">in</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 84.76%); opacity: 0.85\" title=\"-0.204\">certain</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.46%); opacity: 0.82\" title=\"-0.089\">places</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 97.37%); opacity: 0.80\" title=\"-0.017\">with</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 91.23%); opacity: 0.82\" title=\"-0.093\">different</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.72%); opacity: 0.82\" title=\"0.071\">temparatures</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 92.49%); opacity: 0.82\" title=\"0.074\">effects</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 82.94%); opacity: 0.86\" title=\"0.240\">how</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 63.34%); opacity: 0.98\" title=\"0.716\">much</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 91.68%); opacity: 0.82\" title=\"0.086\">the</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 81.74%); opacity: 0.87\" title=\"0.265\">samples</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 86.04%); opacity: 0.84\" title=\"-0.180\">would</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(120, 100.00%, 94.85%); opacity: 0.81\" title=\"0.043\">loose</span><span style=\"opacity: 0.80\"> </span><span style=\"background-color: hsl(0, 100.00%, 79.48%); opacity: 0.88\" title=\"-0.313\">mass</span><span style=\"opacity: 0.80\">.</span>\n",
       "    </p>\n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te = TextExplainer(random_state=42)\n",
    "te.fit(test['EssayText'][438], pipe.predict_proba)\n",
    "te.show_prediction(target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       268\n",
      "          1       1.00      0.97      0.99       309\n",
      "          2       0.99      1.00      0.99       593\n",
      "\n",
      "avg / total       0.99      0.99      0.99      1170\n",
      "\n",
      "accuracy: 0.991\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.49      0.57       112\n",
      "          1       0.24      0.20      0.22       120\n",
      "          2       0.66      0.79      0.72       270\n",
      "\n",
      "avg / total       0.56      0.58      0.56       502\n",
      "\n",
      "accuracy: 0.580\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier()\n",
    "pipe = make_pipeline(count_vectorizer, clf)\n",
    "pipe.fit(train['EssayText'], y_train)\n",
    "\n",
    "print_report(pipe,train['EssayText'], y_train, target_names)\n",
    "\n",
    "print_report(pipe,test['EssayText'], y_test_tmp, target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0732\n",
       "                \n",
       "                    &plusmn; 0.0558\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                __VERB__\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 83.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0551\n",
       "                \n",
       "                    &plusmn; 0.0457\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                __ADV__\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0512\n",
       "                \n",
       "                    &plusmn; 0.0356\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                __NOUN__\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0501\n",
       "                \n",
       "                    &plusmn; 0.0396\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                to\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.67%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0410\n",
       "                \n",
       "                    &plusmn; 0.0193\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                __ADJ__\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.26%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0385\n",
       "                \n",
       "                    &plusmn; 0.0211\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                the\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 87.50%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0374\n",
       "                \n",
       "                    &plusmn; 0.0178\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                of\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.34%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0339\n",
       "                \n",
       "                    &plusmn; 0.0179\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                each\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 88.82%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0319\n",
       "                \n",
       "                    &plusmn; 0.0210\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                in\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 89.61%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0287\n",
       "                \n",
       "                    &plusmn; 0.0173\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                .\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.05%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0270\n",
       "                \n",
       "                    &plusmn; 0.0179\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                i\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.11%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0268\n",
       "                \n",
       "                    &plusmn; 0.0176\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                ,\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.29%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0261\n",
       "                \n",
       "                    &plusmn; 0.0134\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                and\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.44%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0255\n",
       "                \n",
       "                    &plusmn; 0.0108\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                you\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 90.96%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0236\n",
       "                \n",
       "                    &plusmn; 0.0150\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                they\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 90.96%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 249 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(clf, vec=count_vectorizer, top=15,  target_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.feature_selection import RFECV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RFE object and compute a cross-validated score.\n",
    "svc = SVC(kernel=\"linear\")\n",
    "# The \"accuracy\" scoring is proportional to the number of correct\n",
    "# classifications\n",
    "rfecv = RFECV(estimator=svc, step=1, cv=StratifiedKFold(2), scoring='accuracy')\n",
    "rfecv.fit(X_train, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Optimal number of features : %d\" % rfecv.n_features_)\n",
    "\n",
    "# Plot number of features VS. cross-validation scores\n",
    "plt.figure()\n",
    "plt.xlabel(\"Number of features selected\")\n",
    "plt.ylabel(\"Cross validation score (nb of correct classifications)\")\n",
    "plt.plot(range(1, len(rfecv.grid_scores_) + 1), rfecv.grid_scores_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tree Based \n",
    "* Random Forests\n",
    "* GradientBoosted Trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "\n",
    "\n",
    "rf_features = RFECV(RandomForestClassifier(n_estimators=100), cv=StratifiedKFold(5), scoring='f1_weighted')\n",
    "rf_features.fit(X_train, y_train)\n",
    "rf_features.poof()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new matplotlib figure\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot()\n",
    "\n",
    "gb_model = GradientBoostingClassifier().fit(X_train, y_train)\n",
    "feature_importances = gb_model.feature_importances_\n",
    "\n",
    "eli5.show_weights(gb_model,feature_names=feature_names.tolist(), top=50, feature_filter=lambda x: x != '<BIAS>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = SVC(C=150, gamma=2e-2, probability=True)\n",
    "\n",
    "pipe = make_pipeline(clf)\n",
    "pipe.fit(X_train, y_train)\n",
    "pipe.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_prediction(doc):\n",
    "    y_pred = pipe.predict_proba([doc])[0]\n",
    "    #print(y_pred)\n",
    "    for target, prob in zip(y_train, y_pred):\n",
    "        print(\"{:.3f} {}\".format(prob, target))\n",
    "\n",
    "doc = X_train.loc[0,]\n",
    "print_prediction(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sparse_df = pd.SparseDataFrame(X_train)\n",
    "# sparse_df.head()\n",
    "\n",
    "sparse_df.fillna(0,inplace=True)\n",
    "sparse_df.loc[0,].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "te = TextExplainer(random_state=42)\n",
    "te.fit(doc, pipe.predict_proba)\n",
    "te.show_prediction(target_names=twenty_train.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eli5.show_prediction(gb_model, doc=train.iloc[1145,0], ve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_rmsle(y_true, y_pred):\n",
    "#     return np.sqrt(mean_squared_log_error(np.expm1(y_true), np.expm1(y_pred)))\n",
    "\n",
    "cv = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "for train_ids, valid_ids in cv.split(X_train):\n",
    "    model = Ridge(\n",
    "        solver='auto',\n",
    "        fit_intercept=True,\n",
    "        alpha=0.5,\n",
    "        max_iter=100,\n",
    "        normalize=False,\n",
    "        tol=0.05)\n",
    "    model.fit(X_train[train_ids], y_train[train_ids])\n",
    "    y_pred_valid = model.predict(X_train[valid_ids])\n",
    "    rmsle = mean_squared_error(y_test, y_pred)\n",
    "    print(f'valid rmsle: {rmsle:.5f}')\n",
    "    break\n",
    "\n",
    "\n",
    "linear_regressor = LinearRegression()\n",
    "\n",
    "linear_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred = linear_regressor.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', linear_regressor.coef_)\n",
    "\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\" % mean_squared_error(y_test, y_pred))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % linear_regressor.score(X_test, y_test))\n",
    "\n",
    "# Cohen’s kappa score: 1 is complete agreement\n",
    "print('Cohen\\'s kappa score: %.2f' % cohen_kappa_score(np.rint(y_pred), y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stylistics)",
   "language": "python",
   "name": "stylistics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
