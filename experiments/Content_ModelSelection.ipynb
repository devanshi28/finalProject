{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\envs\\stylistics\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings('ignore','.*encoding is deprecated, Use raw=False instead..*')\n",
    "warnings.filterwarnings('ignore','.*the matrix subclass is not the recommended way to represent matrices or deal with linear algebra.*')\n",
    "warnings.filterwarnings('ignore','.*Precision and F-score are ill-defined.*')\n",
    "warnings.filterwarnings('ignore','.*Data with input dtype int64 was converted to float64 by StandardScaler.*')\n",
    "\n",
    "# importing required packages\n",
    "from pathlib import Path\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import _pickle as cPickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "from pprint import pprint\n",
    "from time import time\n",
    "import logging\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import precision_recall_fscore_support, cohen_kappa_score \n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm  import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from imblearn.pipeline import Pipeline as imb_pipeline\n",
    "from sklearn.pipeline import Pipeline as skl_pipeline\n",
    "\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "print(__doc__)\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "np.random.seed(42)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Devanshi\\Desktop\\finalProject\\experiments\\models\n"
     ]
    }
   ],
   "source": [
    "myDir = Path.cwd().parents[0]\n",
    "dataFolder = myDir / 'data/asap-sas'\n",
    "ratingsFolder = myDir / 'data/ratings'\n",
    "figureFolder = myDir / 'figures'\n",
    "modelFolder = myDir /'experiments/models'\n",
    "\n",
    "print(modelFolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EssaySet</th>\n",
       "      <th>subject</th>\n",
       "      <th>studentGrade</th>\n",
       "      <th>EssayText</th>\n",
       "      <th>Score1</th>\n",
       "      <th>styleScore</th>\n",
       "      <th>totalChars</th>\n",
       "      <th>total_words</th>\n",
       "      <th>words_no_punct</th>\n",
       "      <th>words_no_punct_no_stop</th>\n",
       "      <th>count_content_words</th>\n",
       "      <th>count_stopwords</th>\n",
       "      <th>avg_word_len</th>\n",
       "      <th>maturity</th>\n",
       "      <th>concreteness</th>\n",
       "      <th>content_only_text</th>\n",
       "      <th>function_based_text</th>\n",
       "      <th>function_only_text</th>\n",
       "      <th>pos_tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>English</td>\n",
       "      <td>10</td>\n",
       "      <td>One trait that describes rose is hard-working....</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>27</td>\n",
       "      <td>23</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4.173913</td>\n",
       "      <td>5.487419</td>\n",
       "      <td>2.449177</td>\n",
       "      <td>trait  that  describes  rose  is  hard working...</td>\n",
       "      <td>one __NOUN__ __ADJ__ __VERB__ __VERB__ __VERB_...</td>\n",
       "      <td>One  - .  I  this  because  she  to  , but  sh...</td>\n",
       "      <td>NUM NOUN ADJ VERB VERB VERB ADV PUNCT VERB PUN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>English</td>\n",
       "      <td>10</td>\n",
       "      <td>First the author has an introduction to grab t...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>190</td>\n",
       "      <td>38</td>\n",
       "      <td>33</td>\n",
       "      <td>18</td>\n",
       "      <td>20</td>\n",
       "      <td>15</td>\n",
       "      <td>4.666667</td>\n",
       "      <td>5.333607</td>\n",
       "      <td>2.461765</td>\n",
       "      <td>First  author  has  introduction  grab  reader...</td>\n",
       "      <td>__ADV__ the __NOUN__ __VERB__ an __NOUN__ to _...</td>\n",
       "      <td>the  an  to  the  's  .  ,  the  if  in  the  ...</td>\n",
       "      <td>ADV DET NOUN VERB DET NOUN PART VERB DET NOUN ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   EssaySet  subject  studentGrade  \\\n",
       "0         7  English            10   \n",
       "1         9  English            10   \n",
       "\n",
       "                                           EssayText  Score1  styleScore  \\\n",
       "0  One trait that describes rose is hard-working....       1           1   \n",
       "1  First the author has an introduction to grab t...       1           1   \n",
       "\n",
       "   totalChars  total_words  words_no_punct  words_no_punct_no_stop  \\\n",
       "0         120           27              23                      12   \n",
       "1         190           38              33                      18   \n",
       "\n",
       "   count_content_words  count_stopwords  avg_word_len  maturity  concreteness  \\\n",
       "0                   15               11      4.173913  5.487419      2.449177   \n",
       "1                   20               15      4.666667  5.333607      2.461765   \n",
       "\n",
       "                                   content_only_text  \\\n",
       "0  trait  that  describes  rose  is  hard working...   \n",
       "1  First  author  has  introduction  grab  reader...   \n",
       "\n",
       "                                 function_based_text  \\\n",
       "0  one __NOUN__ __ADJ__ __VERB__ __VERB__ __VERB_...   \n",
       "1  __ADV__ the __NOUN__ __VERB__ an __NOUN__ to _...   \n",
       "\n",
       "                                  function_only_text  \\\n",
       "0  One  - .  I  this  because  she  to  , but  sh...   \n",
       "1  the  an  to  the  's  .  ,  the  if  in  the  ...   \n",
       "\n",
       "                                            pos_tags  \n",
       "0  NUM NOUN ADJ VERB VERB VERB ADV PUNCT VERB PUN...  \n",
       "1  ADV DET NOUN VERB DET NOUN PART VERB DET NOUN ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(dataFolder/'training.csv', header=0)  #read data into dataframe\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10895, 19)\n",
      "(10895, 1) (10895,)\n"
     ]
    }
   ],
   "source": [
    "# Take only essay set 1\n",
    "df = df[~(df.subject == 'Biology')]\n",
    "print(df.shape)\n",
    "\n",
    "X = df[['EssayText','Score1']].copy()\n",
    "X.reset_index(drop=True,inplace=True)\n",
    "y= X.pop('Score1')\n",
    "\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments around Features and Hyper Parameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Custom features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) BoW & TF.IDF (n-grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pipeline(smote_on, clf):\n",
    "    \n",
    "    #Do smote sampling\n",
    "    if smote_on == 1:\n",
    "        pipeline = imb_pipeline([('vect',CountVectorizer()),\n",
    "                                 ('smote', SMOTE(ratio='auto',random_state=random_state)),\n",
    "                                 ('tfidf', TfidfTransformer(smooth_idf=True)),\n",
    "                                 (model_name,clf)\n",
    "                                  ])\n",
    "        \n",
    "    #No smote sampling\n",
    "    else:\n",
    "        pipeline = skl_pipeline([('vect',CountVectorizer()),\n",
    "                             ('tfidf', TfidfTransformer(smooth_idf=True)),\n",
    "                             (model_name,clf)\n",
    "                              ])\n",
    "\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#======================EXPERIMENT CONFIG===================\n",
    "experiment_name = 'gridSearch_Content'\n",
    "text_column = 'EssayText'\n",
    "\n",
    "\n",
    "#Models\n",
    "models = [('LogR', LogisticRegression(random_state=random_state, multi_class='multinomial',\n",
    "                                      class_weight='balanced', solver='newton-cg')),\n",
    "         ('NB', MultinomialNB()),\n",
    "          ('SVM',SVC(random_state=random_state, class_weight='balanced')),\n",
    "         ('RF',RandomForestClassifier(random_state=random_state, class_weight='balanced'))]\n",
    "\n",
    "#,'LogR__max_iter':[50,100,150]\n",
    "#,'SVM__gamma':[0.1,1,10]\n",
    "model_params = {'LogR':{'LogR__C':[1,0.1,0.01]},\n",
    "                  'NB':{'NB__alpha':[1,0.5,0.1]},\n",
    "                  'SVM':{'SVM__kernel':['linear','rbf'], 'SVM__C':[0.1,1,10]},\n",
    "                  'RF':{'RF__n_estimators':[50,100,150], 'RF__max_depth':[50,100,500] }\n",
    "                 }\n",
    " \n",
    "# Vectoriser Parameters for Grid Search\n",
    "vect_params = {'vect__max_df': (0.9, 1.0),\n",
    "              'vect__max_features': (None, 8000), \n",
    "              'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "              'vect__stop_words':(None,'english'),\n",
    "              'tfidf__use_idf': (True, False)\n",
    "              }\n",
    "\n",
    "\n",
    "#Use f1-micro and Cohen's Kappa for Grid search evaluations\n",
    "scoring = {'f1-micro':  make_scorer(f1_score, average='micro'),\n",
    "           'cohens_kappa': make_scorer(cohen_kappa_score)}\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================LogR================\n",
      "\n",
      "----------English----------\n",
      "(4296, 1) (4296,)\n",
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'LogR']\n",
      "parameters:\n",
      "{'LogR__C': [1, 0.1, 0.01],\n",
      " 'tfidf__use_idf': (True, False),\n",
      " 'vect__max_df': (0.9, 1.0),\n",
      " 'vect__max_features': (None, 8000),\n",
      " 'vect__ngram_range': ((1, 1), (1, 2)),\n",
      " 'vect__stop_words': (None, 'english')}\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   34.9s\n"
     ]
    }
   ],
   "source": [
    "# For each model\n",
    "for model_name, clf in models:\n",
    "    print('\\n================{}================'.format(model_name))\n",
    "        \n",
    "    #Empty array to store results\n",
    "    tmp_results = []\n",
    "    \n",
    "    #for each subject\n",
    "    for subject in list(df.subject.unique()):\n",
    "        print('\\n----------{}----------'.format(subject))\n",
    "\n",
    "        X = df[(df['subject'] == subject)][[text_column,'Score1']].copy()\n",
    "        X.reset_index(drop=True,inplace=True)\n",
    "        y= X.pop('Score1')\n",
    "\n",
    "        target_names = [str(i) for i in sorted(y.unique())] #Convert to string\n",
    "\n",
    "        print(X.shape, y.shape)\n",
    "        \n",
    "        \n",
    "        #for SMOTE sampling true or false\n",
    "        for smote_on in range(0,2):\n",
    "            \n",
    "            parameters = {}\n",
    "            \n",
    "            myrow = {'Subject':subject, 'Model':model_name, 'Smote':smote_on}\n",
    "         \n",
    "            pipeline = get_pipeline(smote_on, clf)\n",
    "            \n",
    "            #Update parameters for classifier\n",
    "            parameters.update(vect_params)\n",
    "            parameters.update(model_params[model_name])\n",
    "            \n",
    "            #----------------------------GRID SEARCH ----------------------------------------------\n",
    "            grid_search = GridSearchCV(pipeline, parameters, scoring=scoring, refit='cohens_kappa',\n",
    "                                        cv=5, n_jobs=-1, verbose=1, return_train_score=True) \n",
    "\n",
    "            print(\"Performing grid search...\")\n",
    "            print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "            print(\"parameters:\")\n",
    "            pprint(parameters)\n",
    "        \n",
    "            t0 = time()\n",
    "            grid_search.fit(X[text_column], y)\n",
    "            print(\"done in %0.3fs\" % (time() - t0))\n",
    "            \n",
    "            \n",
    "            print(\"\\nBest score: %0.3f\" % grid_search.best_score_)\n",
    "            print(\"Best parameters set:\")\n",
    "            best_parameters = grid_search.best_estimator_.get_params()\n",
    "\n",
    "            for param_name in sorted(parameters.keys()):\n",
    "                print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "        \n",
    "            # get results\n",
    "            myrow.update(grid_search.cv_results_)            \n",
    "\n",
    "            #append results into list\n",
    "            tmp_results.append(myrow)\n",
    "            \n",
    "            #Save the best estimator for each subject & model\n",
    "            with open(modelFolder/'{}_{}_content.pkl'.format(subject,model_name), 'wb') as fid:\n",
    "                cPickle.dump(grid_search.best_estimator_, fid)    \n",
    "            \n",
    "    #Save the results in excel\n",
    "    results = pd.Dataframe(tmp_results)\n",
    "    \n",
    "    writer = pd.ExcelWriter(modelFolder/'{}_content_GS.xlsx'.format(model_name))\n",
    "    results.to_excel(writer,'Sheet1')\n",
    "    writer.save()\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing grid search...\n",
      "pipeline: ['vect', 'tfidf', 'resampler', 'clf']\n",
      "parameters:\n",
      "{'vect__max_df': (0.5, 0.75, 1.0), 'vect__max_features': (None, 5000)}\n",
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   22.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 23.631s\n",
      "\n",
      "Best score: 0.488\n",
      "Best parameters set:\n",
      "\tvect__max_df: 0.75\n",
      "\tvect__max_features: None\n"
     ]
    }
   ],
   "source": [
    "# #############################################################################\n",
    "# Define a pipeline combining a text feature extractor with a simple classifier\n",
    "pipeline = imb_pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('resampler',SMOTE(ratio='all',random_state=random_state)),\n",
    "    ('clf', LogisticRegression(random_state=42,multi_class='multinomial', solver='newton-cg')),\n",
    "])\n",
    "\n",
    "# uncommenting more parameters will give better exploring power but will\n",
    "# increase processing time in a combinatorial way\n",
    "parameters = {\n",
    "    'vect__max_df': (0.5, 0.75, 1.0),\n",
    "    'vect__max_features': (None, 5000)\n",
    "#     ,\n",
    "#     'vect__ngram_range': ((1, 1), (1, 2)),  # unigrams or bigrams\n",
    "#     'vect__stop_words':(None,'english'),\n",
    "#     'tfidf__use_idf': (True, False),\n",
    "# #     'clf__max_iter': (50,100,150),\n",
    "#     'clf__C': (0.1,0.001),\n",
    "}\n",
    "\n",
    "# find the best parameters for both the feature extraction and the classifier\n",
    "grid_search = GridSearchCV(pipeline, parameters, scoring=scoring, refit='cohens_kappa',\n",
    "                           cv=5, n_jobs=-1, verbose=1, return_train_score=True) \n",
    "\n",
    "print(\"Performing grid search...\")\n",
    "print(\"pipeline:\", [name for name, _ in pipeline.steps])\n",
    "print(\"parameters:\")\n",
    "pprint(parameters)\n",
    "t0 = time()\n",
    "grid_search.fit(X.EssayText, y)\n",
    "print(\"done in %0.3fs\" % (time() - t0))\n",
    "print()\n",
    "\n",
    "print(\"Best score: %0.3f\" % grid_search.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = grid_search.best_estimator_.get_params()\n",
    "for param_name in sorted(parameters.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('vect', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=0.75, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        stri...alty='l2', random_state=42, solver='newton-cg',\n",
       "          tol=0.0001, verbose=0, warm_start=False))])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.48827234700588906"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# save the classifier\n",
    "with open(modelFolder/'testing_classifier.pkl', 'wb') as fid:\n",
    "    cPickle.dump(grid_search.best_estimator_, fid)    \n",
    "\n",
    "# load it again\n",
    "# with open('my_dumped_classifier.pkl', 'rb') as fid:\n",
    "#     gnb_loaded = cPickle.load(fid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Model</th>\n",
       "      <th>Smote</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vect__max_df</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_cohens_kappa</th>\n",
       "      <th>std_test_cohens_kappa</th>\n",
       "      <th>rank_test_cohens_kappa</th>\n",
       "      <th>split0_train_cohens_kappa</th>\n",
       "      <th>split1_train_cohens_kappa</th>\n",
       "      <th>split2_train_cohens_kappa</th>\n",
       "      <th>split3_train_cohens_kappa</th>\n",
       "      <th>split4_train_cohens_kappa</th>\n",
       "      <th>mean_train_cohens_kappa</th>\n",
       "      <th>std_train_cohens_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>English</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>1.458831</td>\n",
       "      <td>0.197223</td>\n",
       "      <td>0.184738</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__max_df': 0.5, 'vect__max_features': None}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483410</td>\n",
       "      <td>0.035603</td>\n",
       "      <td>6</td>\n",
       "      <td>0.748034</td>\n",
       "      <td>0.741879</td>\n",
       "      <td>0.735919</td>\n",
       "      <td>0.742846</td>\n",
       "      <td>0.739428</td>\n",
       "      <td>0.741621</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>English</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>1.495641</td>\n",
       "      <td>0.039982</td>\n",
       "      <td>0.187302</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'vect__max_df': 0.5, 'vect__max_features': 5000}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485109</td>\n",
       "      <td>0.038627</td>\n",
       "      <td>5</td>\n",
       "      <td>0.742376</td>\n",
       "      <td>0.736173</td>\n",
       "      <td>0.734622</td>\n",
       "      <td>0.739368</td>\n",
       "      <td>0.731145</td>\n",
       "      <td>0.736737</td>\n",
       "      <td>0.003867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>English</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>1.586230</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.189941</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.75</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__max_df': 0.75, 'vect__max_features': N...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488272</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743665</td>\n",
       "      <td>0.740591</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.740618</td>\n",
       "      <td>0.724567</td>\n",
       "      <td>0.736888</td>\n",
       "      <td>0.006767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>English</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>1.557021</td>\n",
       "      <td>0.036691</td>\n",
       "      <td>0.184569</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'vect__max_df': 0.75, 'vect__max_features': 5...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485507</td>\n",
       "      <td>0.034119</td>\n",
       "      <td>3</td>\n",
       "      <td>0.738896</td>\n",
       "      <td>0.738815</td>\n",
       "      <td>0.730651</td>\n",
       "      <td>0.734946</td>\n",
       "      <td>0.717107</td>\n",
       "      <td>0.732083</td>\n",
       "      <td>0.008078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>English</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>1.573363</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.193581</td>\n",
       "      <td>0.016257</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__max_df': 1.0, 'vect__max_features': None}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488272</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743665</td>\n",
       "      <td>0.740591</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.740618</td>\n",
       "      <td>0.724567</td>\n",
       "      <td>0.736888</td>\n",
       "      <td>0.006767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>English</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>1.551547</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.176738</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'vect__max_df': 1.0, 'vect__max_features': 5000}</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485507</td>\n",
       "      <td>0.034119</td>\n",
       "      <td>3</td>\n",
       "      <td>0.738896</td>\n",
       "      <td>0.738815</td>\n",
       "      <td>0.730651</td>\n",
       "      <td>0.734946</td>\n",
       "      <td>0.717107</td>\n",
       "      <td>0.732083</td>\n",
       "      <td>0.008078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject                Model  Smote  mean_fit_time  std_fit_time  \\\n",
       "0  English  Logistic Regression      1       1.458831      0.197223   \n",
       "1  English  Logistic Regression      1       1.495641      0.039982   \n",
       "2  English  Logistic Regression      1       1.586230      0.013895   \n",
       "3  English  Logistic Regression      1       1.557021      0.036691   \n",
       "4  English  Logistic Regression      1       1.573363      0.031348   \n",
       "5  English  Logistic Regression      1       1.551547      0.016249   \n",
       "\n",
       "   mean_score_time  std_score_time param_vect__max_df  \\\n",
       "0         0.184738        0.003708                0.5   \n",
       "1         0.187302        0.006626                0.5   \n",
       "2         0.189941        0.011050               0.75   \n",
       "3         0.184569        0.003592               0.75   \n",
       "4         0.193581        0.016257                  1   \n",
       "5         0.176738        0.009753                  1   \n",
       "\n",
       "  param_vect__max_features                                             params  \\\n",
       "0                     None  {'vect__max_df': 0.5, 'vect__max_features': None}   \n",
       "1                     5000  {'vect__max_df': 0.5, 'vect__max_features': 5000}   \n",
       "2                     None  {'vect__max_df': 0.75, 'vect__max_features': N...   \n",
       "3                     5000  {'vect__max_df': 0.75, 'vect__max_features': 5...   \n",
       "4                     None  {'vect__max_df': 1.0, 'vect__max_features': None}   \n",
       "5                     5000  {'vect__max_df': 1.0, 'vect__max_features': 5000}   \n",
       "\n",
       "            ...            mean_test_cohens_kappa  std_test_cohens_kappa  \\\n",
       "0           ...                          0.483410               0.035603   \n",
       "1           ...                          0.485109               0.038627   \n",
       "2           ...                          0.488272               0.033995   \n",
       "3           ...                          0.485507               0.034119   \n",
       "4           ...                          0.488272               0.033995   \n",
       "5           ...                          0.485507               0.034119   \n",
       "\n",
       "   rank_test_cohens_kappa  split0_train_cohens_kappa  \\\n",
       "0                       6                   0.748034   \n",
       "1                       5                   0.742376   \n",
       "2                       1                   0.743665   \n",
       "3                       3                   0.738896   \n",
       "4                       1                   0.743665   \n",
       "5                       3                   0.738896   \n",
       "\n",
       "   split1_train_cohens_kappa  split2_train_cohens_kappa  \\\n",
       "0                   0.741879                   0.735919   \n",
       "1                   0.736173                   0.734622   \n",
       "2                   0.740591                   0.735000   \n",
       "3                   0.738815                   0.730651   \n",
       "4                   0.740591                   0.735000   \n",
       "5                   0.738815                   0.730651   \n",
       "\n",
       "   split3_train_cohens_kappa  split4_train_cohens_kappa  \\\n",
       "0                   0.742846                   0.739428   \n",
       "1                   0.739368                   0.731145   \n",
       "2                   0.740618                   0.724567   \n",
       "3                   0.734946                   0.717107   \n",
       "4                   0.740618                   0.724567   \n",
       "5                   0.734946                   0.717107   \n",
       "\n",
       "   mean_train_cohens_kappa  std_train_cohens_kappa  \n",
       "0                 0.741621                0.004000  \n",
       "1                 0.736737                0.003867  \n",
       "2                 0.736888                0.006767  \n",
       "3                 0.732083                0.008078  \n",
       "4                 0.736888                0.006767  \n",
       "5                 0.732083                0.008078  \n",
       "\n",
       "[6 rows x 40 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "pd.DataFrame(myrow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_vect__max_df</th>\n",
       "      <th>param_vect__max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_f1-macro</th>\n",
       "      <th>split1_test_f1-macro</th>\n",
       "      <th>split2_test_f1-macro</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_cohens_kappa</th>\n",
       "      <th>std_test_cohens_kappa</th>\n",
       "      <th>rank_test_cohens_kappa</th>\n",
       "      <th>split0_train_cohens_kappa</th>\n",
       "      <th>split1_train_cohens_kappa</th>\n",
       "      <th>split2_train_cohens_kappa</th>\n",
       "      <th>split3_train_cohens_kappa</th>\n",
       "      <th>split4_train_cohens_kappa</th>\n",
       "      <th>mean_train_cohens_kappa</th>\n",
       "      <th>std_train_cohens_kappa</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.458831</td>\n",
       "      <td>0.197223</td>\n",
       "      <td>0.184738</td>\n",
       "      <td>0.003708</td>\n",
       "      <td>0.5</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__max_df': 0.5, 'vect__max_features': None}</td>\n",
       "      <td>0.614089</td>\n",
       "      <td>0.659351</td>\n",
       "      <td>0.660316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.483410</td>\n",
       "      <td>0.035603</td>\n",
       "      <td>6</td>\n",
       "      <td>0.748034</td>\n",
       "      <td>0.741879</td>\n",
       "      <td>0.735919</td>\n",
       "      <td>0.742846</td>\n",
       "      <td>0.739428</td>\n",
       "      <td>0.741621</td>\n",
       "      <td>0.004000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.495641</td>\n",
       "      <td>0.039982</td>\n",
       "      <td>0.187302</td>\n",
       "      <td>0.006626</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'vect__max_df': 0.5, 'vect__max_features': 5000}</td>\n",
       "      <td>0.612016</td>\n",
       "      <td>0.670881</td>\n",
       "      <td>0.663500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485109</td>\n",
       "      <td>0.038627</td>\n",
       "      <td>5</td>\n",
       "      <td>0.742376</td>\n",
       "      <td>0.736173</td>\n",
       "      <td>0.734622</td>\n",
       "      <td>0.739368</td>\n",
       "      <td>0.731145</td>\n",
       "      <td>0.736737</td>\n",
       "      <td>0.003867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.586230</td>\n",
       "      <td>0.013895</td>\n",
       "      <td>0.189941</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.75</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__max_df': 0.75, 'vect__max_features': N...</td>\n",
       "      <td>0.622326</td>\n",
       "      <td>0.668459</td>\n",
       "      <td>0.664109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488272</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743665</td>\n",
       "      <td>0.740591</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.740618</td>\n",
       "      <td>0.724567</td>\n",
       "      <td>0.736888</td>\n",
       "      <td>0.006767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.557021</td>\n",
       "      <td>0.036691</td>\n",
       "      <td>0.184569</td>\n",
       "      <td>0.003592</td>\n",
       "      <td>0.75</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'vect__max_df': 0.75, 'vect__max_features': 5...</td>\n",
       "      <td>0.618829</td>\n",
       "      <td>0.667661</td>\n",
       "      <td>0.661506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485507</td>\n",
       "      <td>0.034119</td>\n",
       "      <td>3</td>\n",
       "      <td>0.738896</td>\n",
       "      <td>0.738815</td>\n",
       "      <td>0.730651</td>\n",
       "      <td>0.734946</td>\n",
       "      <td>0.717107</td>\n",
       "      <td>0.732083</td>\n",
       "      <td>0.008078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.573363</td>\n",
       "      <td>0.031348</td>\n",
       "      <td>0.193581</td>\n",
       "      <td>0.016257</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>{'vect__max_df': 1.0, 'vect__max_features': None}</td>\n",
       "      <td>0.622326</td>\n",
       "      <td>0.668459</td>\n",
       "      <td>0.664109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488272</td>\n",
       "      <td>0.033995</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743665</td>\n",
       "      <td>0.740591</td>\n",
       "      <td>0.735000</td>\n",
       "      <td>0.740618</td>\n",
       "      <td>0.724567</td>\n",
       "      <td>0.736888</td>\n",
       "      <td>0.006767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.551547</td>\n",
       "      <td>0.016249</td>\n",
       "      <td>0.176738</td>\n",
       "      <td>0.009753</td>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>{'vect__max_df': 1.0, 'vect__max_features': 5000}</td>\n",
       "      <td>0.618829</td>\n",
       "      <td>0.667661</td>\n",
       "      <td>0.661506</td>\n",
       "      <td>...</td>\n",
       "      <td>0.485507</td>\n",
       "      <td>0.034119</td>\n",
       "      <td>3</td>\n",
       "      <td>0.738896</td>\n",
       "      <td>0.738815</td>\n",
       "      <td>0.730651</td>\n",
       "      <td>0.734946</td>\n",
       "      <td>0.717107</td>\n",
       "      <td>0.732083</td>\n",
       "      <td>0.008078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.458831      0.197223         0.184738        0.003708   \n",
       "1       1.495641      0.039982         0.187302        0.006626   \n",
       "2       1.586230      0.013895         0.189941        0.011050   \n",
       "3       1.557021      0.036691         0.184569        0.003592   \n",
       "4       1.573363      0.031348         0.193581        0.016257   \n",
       "5       1.551547      0.016249         0.176738        0.009753   \n",
       "\n",
       "  param_vect__max_df param_vect__max_features  \\\n",
       "0                0.5                     None   \n",
       "1                0.5                     5000   \n",
       "2               0.75                     None   \n",
       "3               0.75                     5000   \n",
       "4                  1                     None   \n",
       "5                  1                     5000   \n",
       "\n",
       "                                              params  split0_test_f1-macro  \\\n",
       "0  {'vect__max_df': 0.5, 'vect__max_features': None}              0.614089   \n",
       "1  {'vect__max_df': 0.5, 'vect__max_features': 5000}              0.612016   \n",
       "2  {'vect__max_df': 0.75, 'vect__max_features': N...              0.622326   \n",
       "3  {'vect__max_df': 0.75, 'vect__max_features': 5...              0.618829   \n",
       "4  {'vect__max_df': 1.0, 'vect__max_features': None}              0.622326   \n",
       "5  {'vect__max_df': 1.0, 'vect__max_features': 5000}              0.618829   \n",
       "\n",
       "   split1_test_f1-macro  split2_test_f1-macro           ...            \\\n",
       "0              0.659351              0.660316           ...             \n",
       "1              0.670881              0.663500           ...             \n",
       "2              0.668459              0.664109           ...             \n",
       "3              0.667661              0.661506           ...             \n",
       "4              0.668459              0.664109           ...             \n",
       "5              0.667661              0.661506           ...             \n",
       "\n",
       "   mean_test_cohens_kappa  std_test_cohens_kappa  rank_test_cohens_kappa  \\\n",
       "0                0.483410               0.035603                       6   \n",
       "1                0.485109               0.038627                       5   \n",
       "2                0.488272               0.033995                       1   \n",
       "3                0.485507               0.034119                       3   \n",
       "4                0.488272               0.033995                       1   \n",
       "5                0.485507               0.034119                       3   \n",
       "\n",
       "   split0_train_cohens_kappa  split1_train_cohens_kappa  \\\n",
       "0                   0.748034                   0.741879   \n",
       "1                   0.742376                   0.736173   \n",
       "2                   0.743665                   0.740591   \n",
       "3                   0.738896                   0.738815   \n",
       "4                   0.743665                   0.740591   \n",
       "5                   0.738896                   0.738815   \n",
       "\n",
       "   split2_train_cohens_kappa  split3_train_cohens_kappa  \\\n",
       "0                   0.735919                   0.742846   \n",
       "1                   0.734622                   0.739368   \n",
       "2                   0.735000                   0.740618   \n",
       "3                   0.730651                   0.734946   \n",
       "4                   0.735000                   0.740618   \n",
       "5                   0.730651                   0.734946   \n",
       "\n",
       "   split4_train_cohens_kappa  mean_train_cohens_kappa  std_train_cohens_kappa  \n",
       "0                   0.739428                 0.741621                0.004000  \n",
       "1                   0.731145                 0.736737                0.003867  \n",
       "2                   0.724567                 0.736888                0.006767  \n",
       "3                   0.717107                 0.732083                0.008078  \n",
       "4                   0.724567                 0.736888                0.006767  \n",
       "5                   0.717107                 0.732083                0.008078  \n",
       "\n",
       "[6 rows x 37 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(grid_search.cv_results_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (stylistics)",
   "language": "python",
   "name": "stylistics"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
